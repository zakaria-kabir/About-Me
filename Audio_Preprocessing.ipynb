{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zakaria-kabir/About-Me/blob/main/Audio_Preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azFIQQMcOWVq"
      },
      "source": [
        "#**Mounting**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YQDvdi6NORku",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2c4c354-369b-4c21-f6a2-c185dbdaf3d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import google.colab\n",
        "import sys\n",
        "\n",
        "# mounting Google Drive in the runtime's virtual machine\n",
        "if not os.path.isdir('/content/drive'):\n",
        "\n",
        "    google.colab.drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0rG0SxYrOc6g"
      },
      "outputs": [],
      "source": [
        "os.chdir('/content/drive/MyDrive/Research 2021/G9 1920392_Zannat Chowdhury_1921371_Md Zakaria Kabir/Development')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7Z8aBe3Ot7m",
        "outputId": "55b1131a-fec5-4d2a-deff-a370f43710cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Audio_Preprocessing.ipynb  input_directory  playlist_collaboration_link.gdoc\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8YP26HSOy-z"
      },
      "source": [
        "#**Installation & Imports**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5JrigxAO2Fy"
      },
      "source": [
        "**Standard Imports**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pubbAoCpO6F5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import json\n",
        "import re\n",
        "import csv\n",
        "import tensorflow as tf # for using gpu in nr_process\n",
        "from google.colab import output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6wFxbrwO7fX"
      },
      "source": [
        "**Other Imports**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3IoUbIyoO9z6"
      },
      "outputs": [],
      "source": [
        "modules = {'librosa': False,\n",
        "           'pandas': False,\n",
        "           'audio_metadata': False,\n",
        "           'yt_dlp': False,\n",
        "           'numpy': False,\n",
        "           'soundfile': False,\n",
        "           'pydub': False,\n",
        "           'spleeter': False,}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bRJGGI8GPBRH"
      },
      "outputs": [],
      "source": [
        "while True:\n",
        "\n",
        "  try:\n",
        "\n",
        "    import librosa\n",
        "    modules['librosa'] = True\n",
        "\n",
        "    import pandas as pd\n",
        "    modules['pandas'] = True\n",
        "\n",
        "    import audio_metadata\n",
        "    modules['audio_metadata'] = True\n",
        "\n",
        "    import yt_dlp\n",
        "    modules['yt_dlp'] = True\n",
        "\n",
        "    import numpy as np\n",
        "    modules['numpy'] = True\n",
        "\n",
        "    import soundfile as sf\n",
        "    modules['soundfile'] = True\n",
        "\n",
        "    from pydub import AudioSegment\n",
        "    from pydub.utils import make_chunks\n",
        "    modules['pydub'] = True\n",
        "\n",
        "    from spleeter.separator import Separator\n",
        "    modules['spleeter'] = True\n",
        "\n",
        "    print('Successfully Imported!!')\n",
        "\n",
        "    break\n",
        "\n",
        "  except Exception:\n",
        "\n",
        "    if modules['librosa'] == False:\n",
        "\n",
        "      print('Installing librosa')\n",
        "\n",
        "      !pip install librosa\n",
        "\n",
        "      continue\n",
        "\n",
        "    if modules['pandas'] == False:\n",
        "\n",
        "      print('Installing pandas')\n",
        "\n",
        "      !pip install pandas\n",
        "\n",
        "      continue\n",
        "\n",
        "    if modules['audio_metadata'] == False:\n",
        "\n",
        "      print('Installing audio_metadata')\n",
        "\n",
        "      !pip install -U audio_metadata\n",
        "\n",
        "      continue\n",
        "\n",
        "    if modules['yt_dlp'] == False:\n",
        "\n",
        "      print('Installing yt_dlp')\n",
        "\n",
        "      !python3 -m pip install -U yt-dlp\n",
        "\n",
        "      continue\n",
        "\n",
        "    if modules['numpy'] == False:\n",
        "\n",
        "      print('Installing numpy')\n",
        "\n",
        "      !pip install numpy\n",
        "\n",
        "      continue\n",
        "\n",
        "    if modules['soundfile'] == False:\n",
        "\n",
        "      print('Installing soundfile')\n",
        "\n",
        "      !pip install soundfile\n",
        "\n",
        "      continue\n",
        "\n",
        "    if modules['pydub'] == False:\n",
        "\n",
        "      print('Installing pydub')\n",
        "\n",
        "      !pip install pydub\n",
        "\n",
        "      continue\n",
        "\n",
        "    if modules['spleeter'] == False:\n",
        "\n",
        "      print('Installing spleeter')\n",
        "\n",
        "      !apt install ffmpeg\n",
        "\n",
        "      !pip install spleeter\n",
        "\n",
        "      continue\n",
        "    print('Packages Installed Successfully')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Klg_-RbP10Q"
      },
      "source": [
        "#**Initialization**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oVehbKh8PqEM"
      },
      "outputs": [],
      "source": [
        "root_directory = '/content/drive/MyDrive/Research 2021/G9 1920392_Zannat Chowdhury_1921371_Md Zakaria Kabir/Development'\n",
        "\n",
        "os.makedirs(root_directory, exist_ok=True)\n",
        "\n",
        "input_directory = os.path.join(root_directory, 'input_directory')\n",
        "\n",
        "os.makedirs(input_directory, exist_ok=True)\n",
        "\n",
        "source_directory = os.path.join(input_directory, 'source_directory')\n",
        "\n",
        "os.makedirs(source_directory, exist_ok=True)\n",
        "\n",
        "trimmed_output = os.path.join(input_directory, 'trimmed_output')\n",
        "\n",
        "os.makedirs(trimmed_output, exist_ok=True)\n",
        "\n",
        "segmented_output = os.path.join(input_directory, 'segmented_output')\n",
        "\n",
        "os.makedirs(segmented_output, exist_ok=True)\n",
        "\n",
        "segmented_raw_output = os.path.join(segmented_output, 'Raw Data')\n",
        "\n",
        "os.makedirs(segmented_raw_output, exist_ok=True)\n",
        "\n",
        "segmented_nr_output = os.path.join(segmented_output, 'Noise_Reduced Data')\n",
        "\n",
        "os.makedirs(segmented_nr_output, exist_ok=True)\n",
        "# dialect_list = ['bogura', 'chittagong', 'dinajpur', 'dhaka_old', 'comilla', 'chapai_nawabganj',\n",
        "#  'barishal', 'bagherhat', 'rajshahi', 'jessore', 'khulna', 'kolkata' 'kushtia',\n",
        "#  'manikganj', 'mymensingh', 'noakhali', 'rangpur', 'shatkhira', 'sirajgonj',\n",
        "#  'sylhet']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A4D2fCHJ5tIT"
      },
      "outputs": [],
      "source": [
        "download_files_process = False\n",
        "update_trim_file_process = False\n",
        "trim_audio_data_process = False\n",
        "segment_process = True\n",
        "nr_process = False\n",
        "audio_info_process = False\n",
        "rdata_to_spreadsheets_process = True\n",
        "nrdata_to_spreedsheets_process = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vBE3qlwI-a1"
      },
      "source": [
        "# **Utility Functions**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pisgwlkGAeSV"
      },
      "source": [
        "### Audio Description"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c7CW5fN1I-bB"
      },
      "outputs": [],
      "source": [
        "def get_audio_info(dialect_list, dir, audio_info_process):\n",
        "\n",
        "  if audio_info_process:\n",
        "\n",
        "    audio_info = []\n",
        "\n",
        "    for dialect in dialect_list:\n",
        "\n",
        "      print('Current Dialect: {0}'.format(dialect))\n",
        "\n",
        "      current_dialect_path = os.path.join(dir, dialect)\n",
        "\n",
        "      for audio_path in glob.glob(os.path.join(current_dialect_path, '*.wav')):\n",
        "\n",
        "        data, sampling_rate = librosa.load(audio_path, sr = None, mono=True)\n",
        "\n",
        "        metadata = audio_metadata.load(audio_path)\n",
        "\n",
        "        audio_info.append({'dialect': dialect,\n",
        "                          'filename': audio_path.split('/')[-1],\n",
        "                          'sampling_rate': sampling_rate,\n",
        "                          'duration' : librosa.get_duration(y = data, sr = sampling_rate),\n",
        "                          'audio_shape' : data.shape,\n",
        "                          'n_channels': len(data.shape),\n",
        "                          'filesize': f'{metadata.filesize/1024:.2f} KiB',\n",
        "                          'bit_rate': f'{metadata.streaminfo.bitrate/1000:.1f} Kbps',\n",
        "                          'bit_depth': metadata.streaminfo.bit_depth,\n",
        "                          'filepath' : audio_path\n",
        "                      })\n",
        "\n",
        "    return pd.DataFrame(audio_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2eHNT-5L7Rh"
      },
      "source": [
        "# **Audio download**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OwQ0sxZNOmgv"
      },
      "outputs": [],
      "source": [
        "audio_url = {\n",
        "            'bogura':'https://www.youtube.com/playlist?list=PLh79TXh5wUA2sESaJxMUA-yKB753mnLpV',\n",
        "            'chittagong':'https://youtube.com/playlist?list=PLh79TXh5wUA1JJdT_o9fNuTuwRcW11wuJ',\n",
        "            'dinajpur':'https://www.youtube.com/playlist?list=PLh79TXh5wUA2iTmaHihqGJJXIPVrEvhtB',\n",
        "            'dhaka_old':'https://www.youtube.com/playlist?list=PLh79TXh5wUA2oivE_qqlZnhAdbZhJJ8nc',\n",
        "            'comilla':'https://www.youtube.com/playlist?list=PLh79TXh5wUA0W1NGAHkRxyHUSB9pb7K8O',\n",
        "            'chapai_nawabganj':'https://www.youtube.com/playlist?list=PLh79TXh5wUA3fNAJ9mGUVBF9gaPsYuCwb',\n",
        "            'barishal':'https://www.youtube.com/playlist?list=PLh79TXh5wUA1a9gvYcvnGDU2zT56OfzGj',\n",
        "            'bagerhat':'https://www.youtube.com/playlist?list=PLh79TXh5wUA0Uw-OvaVis7smYIxua_Q10',\n",
        "            'rajshahi':'https://www.youtube.com/playlist?list=PLh79TXh5wUA2dTraJg928KGAKNSaaY-2G',\n",
        "            'jessore':'https://www.youtube.com/playlist?list=PLh79TXh5wUA0RGss5T1EvrpJRxHXrr0_S',\n",
        "            'khulna':'https://www.youtube.com/playlist?list=PLh79TXh5wUA3tgiCsMq0ADkk4qYtLYMZT',\n",
        "            'kolkata':'https://www.youtube.com/playlist?list=PLh79TXh5wUA1X_brXuh6dCrB0Dd3USmwm',\n",
        "            'kushtia':'https://www.youtube.com/playlist?list=PLh79TXh5wUA2KFsndexCHzpxvOapGcyKe',\n",
        "            'manikganj':'https://www.youtube.com/playlist?list=PLh79TXh5wUA2irbH3RgbTO0dx4oxcsKPF',\n",
        "            'mymensingh':'https://www.youtube.com/playlist?list=PLh79TXh5wUA0-zv6ZZHMTyGwx0_iRrnWD',\n",
        "            'noakhali':'https://www.youtube.com/playlist?list=PLh79TXh5wUA1xJCfr-3YmZKKKpGQqopKG',\n",
        "            'rangpur':'https://www.youtube.com/playlist?list=PLh79TXh5wUA0xBXftNohSOmK6aDJG2DOn',\n",
        "            'shathkhira':'https://www.youtube.com/playlist?list=PLh79TXh5wUA3LjmFCWymquAm0ER037AYu',\n",
        "            'sirajgonj':'https://www.youtube.com/playlist?list=PLh79TXh5wUA0mfmyXNRkQRggLneN73cM0',\n",
        "            'sylhet':'https://www.youtube.com/playlist?list=PLh79TXh5wUA22CAiJs8p_p7MssS4kueRe',\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XceUAPvsO4NR"
      },
      "outputs": [],
      "source": [
        "# filepath = os.path.join(source_directory, 'playlist.txt')\n",
        "\n",
        "# with open(filepath, 'w+') as file:\n",
        "\n",
        "#   for key, value in audio_url.items():\n",
        "\n",
        "#     file.write('{0}\\n{1}\\n'.format(key, value))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VjrhbgwJv-sU"
      },
      "outputs": [],
      "source": [
        "# def download_files(download_files_process):\n",
        "\n",
        "#   if download_files_process:\n",
        "\n",
        "#     !yt-dlp -f 'ba' -x --audio-format wav --download-archive '{source_directory}/downloaded_list.txt' -o '{source_directory}/%(playlist)s/%(playlist)s%(playlist_index)05d.%(ext)s' -a '{filepath}'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hx6gFlkmrIR6"
      },
      "outputs": [],
      "source": [
        "def download_files(download_files_process):\n",
        "\n",
        "  if download_files_process:\n",
        "\n",
        "    for key, value in audio_url.items():\n",
        "\n",
        "      !yt-dlp -f 'ba' -x --audio-format wav --download-archive '{source_directory}/{key}/{key}_downloaded_list.txt' -o '{source_directory}/%(playlist)s/%(playlist)s%(playlist_index)05d.%(ext)s' '{value}'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JPkeMSOtshRB"
      },
      "outputs": [],
      "source": [
        "download_files(download_files_process)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xoCOwNontBL3"
      },
      "source": [
        "# **Get Dialect List**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UIQJUr7rRcb9"
      },
      "outputs": [],
      "source": [
        "dialect_list = list(audio_url.keys())\n",
        "\n",
        "short_dialect_dict={\n",
        "  'bogura':'bgr',\n",
        "  'chittagong':'ctg',\n",
        "  'dinajpur':'dnj',\n",
        "  'dhaka_old':'dko',\n",
        "  'comilla':'cml',\n",
        "  'chapai_nawabganj':'chp',\n",
        "  'barishal':'bar',\n",
        "  'bagerhat':'bgh',\n",
        "  'rajshahi':'raj',\n",
        "  'jessore':'jsr',\n",
        "  'khulna':'khl',\n",
        "  'kolkata':'kol',\n",
        "  'kushtia':'kst',\n",
        "  'manikganj':'mnk',\n",
        "  'mymensingh':'mmn',\n",
        "  'noakhali':'nkl',\n",
        "  'rangpur':'rng',\n",
        "  'shathkhira':'stk',\n",
        "  'sirajgonj':'srg',\n",
        "  'sylhet':'syl',\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ck6rJltyRFyq"
      },
      "source": [
        "#**Audio Triming**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4xwnhavZAml"
      },
      "source": [
        "**Initializing Trimming Points**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U21zXvBzW_Gs"
      },
      "outputs": [],
      "source": [
        "def initialize_trimming_points(process):\n",
        "\n",
        "  if process:\n",
        "\n",
        "    trimming_points = {}\n",
        "\n",
        "    for dialect in dialect_list:\n",
        "\n",
        "      current_dialect_path = os.path.join(source_directory, dialect)\n",
        "\n",
        "      for audio_path in sorted(glob.glob(os.path.join(current_dialect_path, '*.wav'))):\n",
        "\n",
        "        trimming_points[audio_path.split('/')[-1]] = None\n",
        "\n",
        "    return trimming_points"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PINtKszisQ8"
      },
      "source": [
        "**Write into file to note down the points**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DjI1qdoTi4I7"
      },
      "outputs": [],
      "source": [
        "def write_trim_points_into_file(trim_points_filename, update_trim_file_process):\n",
        "\n",
        "  if update_trim_file_process:\n",
        "\n",
        "    trimming_points=initialize_trimming_points(update_trim_file_process)\n",
        "\n",
        "    if not os.path.isfile(trim_points_filename) :\n",
        "\n",
        "      fp = open(trim_points_filename, 'x')\n",
        "\n",
        "      fp.close()\n",
        "\n",
        "    if os.stat(trim_points_filename).st_size == 0:\n",
        "\n",
        "      json.dump(trimming_points, open(trim_points_filename,'w'),indent=2, sort_keys=True)\n",
        "\n",
        "    else:\n",
        "\n",
        "      trim_points_dict = json.load(open(os.path.join(source_directory, trim_points_filename)))\n",
        "\n",
        "      if not trim_points_dict.keys()==trimming_points.keys():\n",
        "\n",
        "        trimming_points.update(trim_points_dict)\n",
        "\n",
        "        json.dump(trimming_points, open(trim_points_filename,'w'), indent=2, sort_keys=True, separators=(',', ': '))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgRTg_iQjGqd"
      },
      "source": [
        "**Read file to read the trimming points & trim, & save to trimed directory by same file and folder notation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZvbTtVo0-G4r"
      },
      "outputs": [],
      "source": [
        "def trim_audio_dataset(trim_points_filename, trimmed_output, trim_audio_data_process):\n",
        "\n",
        "  if trim_audio_data_process:\n",
        "\n",
        "    trim_points_dict = json.load(open(trim_points_filename))\n",
        "\n",
        "    for key, points in trim_points_dict.items():\n",
        "\n",
        "      current_dialect = re.split('\\d+', key)[0]\n",
        "\n",
        "      current_filepath = os.path.join(source_directory, current_dialect, key)\n",
        "\n",
        "      current_file_output_directory = os.path.join(trimmed_output, current_dialect)\n",
        "\n",
        "      os.makedirs(current_file_output_directory, exist_ok=True)\n",
        "\n",
        "      audio, sr = librosa.load(current_filepath, sr = None, mono = True)\n",
        "\n",
        "      buffer = 0\n",
        "\n",
        "      if points is not None:\n",
        "\n",
        "        for current_point in points:\n",
        "\n",
        "          current_point = np.array(current_point) - buffer\n",
        "\n",
        "          audio = np.delete(audio,slice(current_point[0]*sr,-1 if current_point[1]<0 else current_point[1]*sr))\n",
        "\n",
        "          buffer += np.diff(current_point)\n",
        "\n",
        "      sf.write(os.path.join(current_file_output_directory, key), audio, sr)\n",
        "\n",
        "      print(os.path.join(current_file_output_directory, key))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5OA3P8A6DdD0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9419eacc-8e2b-482c-8bfe-a465a35394b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Research 2021/G9 1920392_Zannat Chowdhury_1921371_Md Zakaria Kabir/Development/input_directory/trimmed_output/barishal/barishal00001.wav\n",
            "/content/drive/MyDrive/Research 2021/G9 1920392_Zannat Chowdhury_1921371_Md Zakaria Kabir/Development/input_directory/trimmed_output/barishal/barishal00002.wav\n",
            "/content/drive/MyDrive/Research 2021/G9 1920392_Zannat Chowdhury_1921371_Md Zakaria Kabir/Development/input_directory/trimmed_output/barishal/barishal00003.wav\n",
            "/content/drive/MyDrive/Research 2021/G9 1920392_Zannat Chowdhury_1921371_Md Zakaria Kabir/Development/input_directory/trimmed_output/barishal/barishal00004.wav\n",
            "/content/drive/MyDrive/Research 2021/G9 1920392_Zannat Chowdhury_1921371_Md Zakaria Kabir/Development/input_directory/trimmed_output/barishal/barishal00005.wav\n",
            "/content/drive/MyDrive/Research 2021/G9 1920392_Zannat Chowdhury_1921371_Md Zakaria Kabir/Development/input_directory/trimmed_output/barishal/barishal00006.wav\n",
            "/content/drive/MyDrive/Research 2021/G9 1920392_Zannat Chowdhury_1921371_Md Zakaria Kabir/Development/input_directory/trimmed_output/barishal/barishal00007.wav\n",
            "/content/drive/MyDrive/Research 2021/G9 1920392_Zannat Chowdhury_1921371_Md Zakaria Kabir/Development/input_directory/trimmed_output/barishal/barishal00008.wav\n",
            "/content/drive/MyDrive/Research 2021/G9 1920392_Zannat Chowdhury_1921371_Md Zakaria Kabir/Development/input_directory/trimmed_output/barishal/barishal00009.wav\n",
            "/content/drive/MyDrive/Research 2021/G9 1920392_Zannat Chowdhury_1921371_Md Zakaria Kabir/Development/input_directory/trimmed_output/barishal/barishal00010.wav\n",
            "/content/drive/MyDrive/Research 2021/G9 1920392_Zannat Chowdhury_1921371_Md Zakaria Kabir/Development/input_directory/trimmed_output/barishal/barishal00011.wav\n",
            "/content/drive/MyDrive/Research 2021/G9 1920392_Zannat Chowdhury_1921371_Md Zakaria Kabir/Development/input_directory/trimmed_output/barishal/barishal00012.wav\n",
            "/content/drive/MyDrive/Research 2021/G9 1920392_Zannat Chowdhury_1921371_Md Zakaria Kabir/Development/input_directory/trimmed_output/barishal/barishal00013.wav\n",
            "/content/drive/MyDrive/Research 2021/G9 1920392_Zannat Chowdhury_1921371_Md Zakaria Kabir/Development/input_directory/trimmed_output/barishal/barishal00014.wav\n",
            "/content/drive/MyDrive/Research 2021/G9 1920392_Zannat Chowdhury_1921371_Md Zakaria Kabir/Development/input_directory/trimmed_output/barishal/barishal00015.wav\n",
            "/content/drive/MyDrive/Research 2021/G9 1920392_Zannat Chowdhury_1921371_Md Zakaria Kabir/Development/input_directory/trimmed_output/barishal/barishal00016.wav\n",
            "/content/drive/MyDrive/Research 2021/G9 1920392_Zannat Chowdhury_1921371_Md Zakaria Kabir/Development/input_directory/trimmed_output/barishal/barishal00017.wav\n",
            "/content/drive/MyDrive/Research 2021/G9 1920392_Zannat Chowdhury_1921371_Md Zakaria Kabir/Development/input_directory/trimmed_output/barishal/barishal00018.wav\n",
            "/content/drive/MyDrive/Research 2021/G9 1920392_Zannat Chowdhury_1921371_Md Zakaria Kabir/Development/input_directory/trimmed_output/barishal/barishal00019.wav\n",
            "/content/drive/MyDrive/Research 2021/G9 1920392_Zannat Chowdhury_1921371_Md Zakaria Kabir/Development/input_directory/trimmed_output/barishal/barishal00020.wav\n",
            "/content/drive/MyDrive/Research 2021/G9 1920392_Zannat Chowdhury_1921371_Md Zakaria Kabir/Development/input_directory/trimmed_output/barishal/barishal00021.wav\n",
            "/content/drive/MyDrive/Research 2021/G9 1920392_Zannat Chowdhury_1921371_Md Zakaria Kabir/Development/input_directory/trimmed_output/barishal/barishal00022.wav\n",
            "/content/drive/MyDrive/Research 2021/G9 1920392_Zannat Chowdhury_1921371_Md Zakaria Kabir/Development/input_directory/trimmed_output/barishal/barishal00023.wav\n",
            "/content/drive/MyDrive/Research 2021/G9 1920392_Zannat Chowdhury_1921371_Md Zakaria Kabir/Development/input_directory/trimmed_output/barishal/barishal00024.wav\n",
            "/content/drive/MyDrive/Research 2021/G9 1920392_Zannat Chowdhury_1921371_Md Zakaria Kabir/Development/input_directory/trimmed_output/barishal/barishal00025.wav\n",
            "/content/drive/MyDrive/Research 2021/G9 1920392_Zannat Chowdhury_1921371_Md Zakaria Kabir/Development/input_directory/trimmed_output/barishal/barishal00026.wav\n",
            "/content/drive/MyDrive/Research 2021/G9 1920392_Zannat Chowdhury_1921371_Md Zakaria Kabir/Development/input_directory/trimmed_output/barishal/barishal00027.wav\n",
            "/content/drive/MyDrive/Research 2021/G9 1920392_Zannat Chowdhury_1921371_Md Zakaria Kabir/Development/input_directory/trimmed_output/barishal/barishal00028.wav\n",
            "/content/drive/MyDrive/Research 2021/G9 1920392_Zannat Chowdhury_1921371_Md Zakaria Kabir/Development/input_directory/trimmed_output/barishal/barishal00029.wav\n",
            "/content/drive/MyDrive/Research 2021/G9 1920392_Zannat Chowdhury_1921371_Md Zakaria Kabir/Development/input_directory/trimmed_output/barishal/barishal00030.wav\n",
            "/content/drive/MyDrive/Research 2021/G9 1920392_Zannat Chowdhury_1921371_Md Zakaria Kabir/Development/input_directory/trimmed_output/barishal/barishal00031.wav\n",
            "/content/drive/MyDrive/Research 2021/G9 1920392_Zannat Chowdhury_1921371_Md Zakaria Kabir/Development/input_directory/trimmed_output/barishal/barishal00032.wav\n"
          ]
        }
      ],
      "source": [
        "trim_points_filename = os.path.join(source_directory, 'trim_points.json')\n",
        "\n",
        "write_trim_points_into_file(trim_points_filename, update_trim_file_process)\n",
        "\n",
        "trim_audio_dataset(trim_points_filename, trimmed_output, trim_audio_data_process)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KAPZojLuXZ_"
      },
      "source": [
        "# **Audio Splitting**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90tWvE6yAEYt"
      },
      "source": [
        "*error: non-default argument follows default argument\n",
        "correct example*\n",
        "\n",
        "def example(a, b, c=None, r=\"w\", d=[], *ae,  **ab):\n",
        "\n",
        "(a,b) are positional parameter\n",
        "\n",
        "(c=none) is optional parameter\n",
        "\n",
        "(r=\"w\") is keyword parameter\n",
        "\n",
        "(d=[]) is list parameter\n",
        "\n",
        "(*ae) is keyword-only\n",
        "\n",
        "(*ab) is var-keyword parameter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U01LZZoQuWSJ"
      },
      "outputs": [],
      "source": [
        "def split_audio_into_segments(dialect_list, inp_dir, output_dir, segment_process, segment_time=10):\n",
        "\n",
        "  if segment_process:\n",
        "\n",
        "    # segment_time = int(input(\"Enter segment time (in Seconds):\"))\n",
        "\n",
        "    for dialect in dialect_list:\n",
        "\n",
        "      print('Current Dialect: {0}'.format(dialect))\n",
        "\n",
        "      current_dialect_path = os.path.join(inp_dir, dialect)\n",
        "\n",
        "      current_file_output_directory = os.path.join(output_dir, dialect)\n",
        "\n",
        "      os.makedirs(current_file_output_directory, exist_ok=True)\n",
        "\n",
        "      count=0\n",
        "\n",
        "      for audio_path in sorted(glob.glob(os.path.join(current_dialect_path, '*.wav'))):\n",
        "\n",
        "        audio = AudioSegment.from_file(audio_path, \"wav\")\n",
        "\n",
        "        chunk_length_ms = segment_time*1000\n",
        "\n",
        "        chunks = make_chunks(audio,chunk_length_ms)\n",
        "\n",
        "        for chunk in chunks:\n",
        "\n",
        "          if not len(chunk)<(segment_time-2)*1000:\n",
        "\n",
        "            count+=1\n",
        "\n",
        "            chunk_name = os.path.join(current_file_output_directory, \"r_\"+short_dialect_dict.get(dialect)+\"{:05}.wav\".format(count))\n",
        "\n",
        "            chunk.export(chunk_name, format=\"wav\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9O73f8l_v8cj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cbbd5fd-a0c1-4382-9064-6a019576444d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current Dialect: bogura\n",
            "Current Dialect: chittagong\n",
            "Current Dialect: dinajpur\n",
            "Current Dialect: dhaka_old\n",
            "Current Dialect: comilla\n",
            "Current Dialect: chapai_nawabganj\n",
            "Current Dialect: barishal\n",
            "Current Dialect: bagerhat\n",
            "Current Dialect: rajshahi\n",
            "Current Dialect: jessore\n",
            "Current Dialect: khulna\n",
            "Current Dialect: kolkata\n",
            "Current Dialect: kushtia\n",
            "Current Dialect: manikganj\n",
            "Current Dialect: mymensingh\n",
            "Current Dialect: noakhali\n",
            "Current Dialect: rangpur\n",
            "Current Dialect: shathkhira\n",
            "Current Dialect: sirajgonj\n",
            "Current Dialect: sylhet\n"
          ]
        }
      ],
      "source": [
        "split_audio_into_segments(dialect_list, trimmed_output, segmented_raw_output, segment_process)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7MAWM8eNA2SK"
      },
      "outputs": [],
      "source": [
        "audio_info_df = get_audio_info(dialect_list, segmented_raw_output, audio_info_process)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oljrUnBXA3Ne"
      },
      "outputs": [],
      "source": [
        "audio_info_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTKIF3Ef2bR1"
      },
      "source": [
        "# **Noise Reduction of Segmented Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d3J8gjC62ktu"
      },
      "outputs": [],
      "source": [
        "def reduce_noise(dialect_list, inp_dir, output_dir, nr_process):\n",
        "  \n",
        "  if nr_process:\n",
        "    \n",
        "    separator = Separator('spleeter:2stems')\n",
        "\n",
        "    for dialect in dialect_list:\n",
        "\n",
        "      current_dialect_path = os.path.join(inp_dir, dialect)\n",
        "\n",
        "      current_file_output_directory = os.path.join(output_dir, dialect)\n",
        "\n",
        "      os.makedirs(current_file_output_directory, exist_ok=True)\n",
        "\n",
        "      print(current_dialect_path)\n",
        "\n",
        "      for audio_path in sorted(glob.glob(os.path.join(current_dialect_path, '*.wav'))):\n",
        "        \n",
        "        separator.separate_to_file(audio_path,  current_file_output_directory, filename_format=\"{instrument}_{filename}.{codec}\")\n",
        "\n",
        "        output.clear() # couldn't find any other way to supress INFO:spleeter msgs, so clearing the console :(\n",
        "      \n",
        "\n",
        "      for f in glob.glob(os.path.join(current_file_output_directory, '*.wav')):\n",
        "\n",
        "        if 'accompaniment' in f:\n",
        "\n",
        "          os.remove(f)\n",
        "\n",
        "        if 'vocals' in f:\n",
        "\n",
        "          os.rename(f,'{}/nr_{}'.format(current_file_output_directory,f.split('_')[-1]))\n",
        "\n",
        "          print('{}/nr_{}'.format(current_file_output_directory,f.split('_')[-1]))\n",
        "      "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R7TS1JIH4XL1"
      },
      "outputs": [],
      "source": [
        "# with tf.device('/device:GPU:0'):\n",
        "#   reduce_noise(dialect_list, segmented_raw_output, segmented_nr_output, nr_process)\n",
        "reduce_noise(dialect_list, segmented_raw_output, segmented_nr_output, nr_process) #without gpu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOoJoXO-zZU1"
      },
      "source": [
        "# **To  Spreadsheets**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Raw data -> r_data**"
      ],
      "metadata": {
        "id": "Cx3FV5OV_W47"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x1Oa93o_M0XM"
      },
      "outputs": [],
      "source": [
        "def export_rdata_to_spreadsheets(dialect_list, inp_dir, out_dir, to_spreadsheets_process):\n",
        "\n",
        "  if to_spreadsheets_process:\n",
        "\n",
        "    audio_info = []\n",
        "\n",
        "    for dialect in dialect_list:\n",
        "\n",
        "      current_dialect_path = os.path.join(inp_dir, dialect)\n",
        "\n",
        "      for audio_path in sorted(glob.glob(os.path.join(current_dialect_path, '*.wav'))):\n",
        "        \n",
        "        audio_info.append({'filename': audio_path.split('/')[-1],\n",
        "                          'dialect': dialect,})\n",
        "\n",
        "    audio_info_df = pd.DataFrame(audio_info)\n",
        "\n",
        "    spreadsheets_file_path = os.path.join(out_dir, 'data.xlsx')\n",
        "\n",
        "    if os.path.exists(spreadsheets_file_path) and os.stat(spreadsheets_file_path).st_size != 0:\n",
        "\n",
        "      df=pd.read_excel(spreadsheets_file_path)\n",
        "\n",
        "      merged_df = audio_info_df.merge(df, on='filename', how='left').drop(['dialect_y'], axis=1).rename(columns = {'dialect_x': 'dialect'})\n",
        "\n",
        "      headers = merged_df.columns.tolist()\n",
        "\n",
        "      merged_df.to_excel(spreadsheets_file_path, sheet_name='r_data', columns = headers, index=False)\n",
        "\n",
        "    else:\n",
        "\n",
        "      ch = {'gender': '', 'no of speaker': '', 'noise reduced': 'no', 'annotation': ''}\n",
        "\n",
        "      audio_info_df = audio_info_df.assign(**ch)\n",
        "\n",
        "      headers = audio_info_df.columns.tolist()\n",
        "\n",
        "      audio_info_df.to_excel(spreadsheets_file_path, sheet_name='r_data', columns = headers, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9zfBlyEHzezU"
      },
      "outputs": [],
      "source": [
        "export_rdata_to_spreadsheets(dialect_list, segmented_raw_output, segmented_output, rdata_to_spreadsheets_process)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Noise Reduced data -> nr_data**"
      ],
      "metadata": {
        "id": "aIJokXUO_h36"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def export_nrdata_to_spreedsheets(inpt_dir, out_dir, nrdata_to_spreedsheets_process):\n",
        "\n",
        "  if nrdata_to_spreedsheets_process:\n",
        "\n",
        "    filenames = []\n",
        "\n",
        "    for dialect in dialect_list:\n",
        "\n",
        "      current_dialect_path = os.path.join(inpt_dir, dialect)\n",
        "\n",
        "      filenames.extend(sorted(os.listdir(current_dialect_path)))\n",
        "\n",
        "    data = pd.read_excel(out_dir, sheet_name=\"r_data\")\n",
        "\n",
        "    data['filename'], data['noise reduced']=filenames, 'yes'\n",
        "\n",
        "    with pd.ExcelWriter(out_dir, mode='a', if_sheet_exists='replace') as writer:  \n",
        "\n",
        "      data.to_excel(writer, sheet_name='nr_data', index=False)"
      ],
      "metadata": {
        "id": "BXdmU1eowuCR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "export_nrdata_to_spreedsheets(segmented_nr_output, os.path.join(segmented_output,'data.xlsx'), nrdata_to_spreedsheets_process)"
      ],
      "metadata": {
        "id": "KcU1p92IzGtz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzzm4DPlYstS"
      },
      "source": [
        "# **Trial**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DklGpxAqY32B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0be63807-437f-4125-e89d-c4c02954c71a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   F    G gender no of speaker noise type annotation\n",
              "0  B  yes                             raw           \n",
              "1  B  yes                             raw           \n",
              "2  C  yes                             raw           \n",
              "3  C  yes                             raw           \n",
              "4  S  yes                             raw           "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bd893a9b-dee5-491d-abcb-3b0338b90903\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>F</th>\n",
              "      <th>G</th>\n",
              "      <th>gender</th>\n",
              "      <th>no of speaker</th>\n",
              "      <th>noise type</th>\n",
              "      <th>annotation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>B</td>\n",
              "      <td>yes</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>raw</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>B</td>\n",
              "      <td>yes</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>raw</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>C</td>\n",
              "      <td>yes</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>raw</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>C</td>\n",
              "      <td>yes</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>raw</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>S</td>\n",
              "      <td>yes</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>raw</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bd893a9b-dee5-491d-abcb-3b0338b90903')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bd893a9b-dee5-491d-abcb-3b0338b90903 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bd893a9b-dee5-491d-abcb-3b0338b90903');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "df1 = pd.DataFrame(\n",
        "    {\n",
        "        \"F\": [\"B0\", \"B1\", \"C1\", \"C2\",\"S1\"],\n",
        "        \"G\": [\"M\", \"B\", \"F\", \"M\",\"B\"],\n",
        "\n",
        "    },\n",
        ")\n",
        "c = {'gender':'', 'no of speaker':'', 'noise type':'raw', 'annotation':''}\n",
        "\n",
        "df1 = df1.assign(**c)\n",
        "\n",
        "headers = df1.columns.tolist()\n",
        "\n",
        "df1['F'],df1['G']=[\"B\", \"B\", \"C\", \"C\",\"S\"], 'yes'\n",
        "df1\n",
        "\n",
        "# df2 = pd.DataFrame(\n",
        "#     {\n",
        "#         \"F\": [\"B0\", \"B1\", \"B2\", \"C1\", \"C2\",\"C3\", \"S1\", \"S2\"],\n",
        "#         \"G\": [\"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"],\n",
        "#     },\n",
        "# )\n",
        "\n",
        "\n",
        "# frames = [df1, df2]\n",
        "\n",
        "# # df_merged = pd.concat([df1,df2]).drop_duplicates().reset_index(drop=False)\n",
        "# df_merged= df2.merge(df1, on='F', how='left').drop ( ['G_x'], axis=1)\n",
        "# df_merged"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J8HVfnVqL2xq"
      },
      "outputs": [],
      "source": [
        "# sir_root_dir = \"/content/drive/MyDrive/Research 2021/G9 1920392_Zannat Chowdhury_1921371_Md Zakaria Kabir/Abujar Sir's Regional Speech Dataset/regionData\"\n",
        "# barisal = \"/content/drive/MyDrive/Research 2021/G9 1920392_Zannat Chowdhury_1921371_Md Zakaria Kabir/Abujar Sir's Regional Speech Dataset/regionData/Barishal\"\n",
        "# temp_combined = np.array([])\n",
        "# count = 0\n",
        "# test_path = \"/content/drive/MyDrive/Research 2021/G9 1920392_Zannat Chowdhury_1921371_Md Zakaria Kabir/Abujar Sir's Regional Speech Dataset/Test/\"\n",
        "# os.makedirs(test_path, exist_ok=True)\n",
        "# def numericalSort(value):\n",
        "#   return int(re.findall(r'\\d+', value)[-1])\n",
        "\n",
        "# for audio_path in sorted(glob.glob(os.path.join(barisal, '*.wav')),  key=numericalSort):\n",
        "#   # audio = AudioSegment.from_wav(audio_path)\n",
        "#   audio, sr = librosa.load(audio_path, sr = None, mono=True)\n",
        "\n",
        "\n",
        "#   if len(temp_combined)/sr<10.0:\n",
        "#     print(audio_path)\n",
        "#     temp_combined = np.concatenate((temp_combined, audio), axis=None)\n",
        "#   else:\n",
        "#     count+=1\n",
        "#     sf.write(f\"{test_path}/combined_file{count}.wav\", temp_combined, sr)\n",
        "#     temp_combined = audio\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nJ4jut59SuEn"
      },
      "outputs": [],
      "source": [
        "# import csv\n",
        "\n",
        "# def test_write_trim_points_into_file(trim_points_filename, update_trim_file_process=True):\n",
        "\n",
        "#   if update_trim_file_process:\n",
        "\n",
        "#     trimming_points=initialize_trimming_points(update_trim_file_process)\n",
        "\n",
        "#     if not os.path.isfile(trim_points_filename) :\n",
        "\n",
        "#       with open(trim_points_filename, 'w+') as f:\n",
        "#           w = csv.DictWriter(f, trimming_points.keys())\n",
        "#           w.writeheader()\n",
        "#           w.writerow(trimming_points)\n",
        "\n",
        "\n",
        "#     # else:\n",
        "\n",
        "#     #   trim_points_dict = json.load(open(os.path.join(source_directory, trim_points_filename)))\n",
        "\n",
        "#     #   if not trim_points_dict.keys()==trimming_points.keys():\n",
        "\n",
        "#     #     trimming_points.update(trim_points_dict)\n",
        "\n",
        "#     #     json.dump(trimming_points, open(trim_points_filename,'w'), indent=2, sort_keys=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g3-2IRfAS8AU"
      },
      "outputs": [],
      "source": [
        "# trim_points_filename = os.path.join(source_directory, 'test_trim_points.csv')\n",
        "# test_write_trim_points_into_file(trim_points_filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TTfbbNiQXbMG"
      },
      "outputs": [],
      "source": [
        "# import csv\n",
        "\n",
        "# somedict = {\"test1\": [(1,2),(3,4)], \"testing2\": [(1,2),(3,4)], \"testing3\": [(1,2),(3,4)], \"testing4\": '', \"testing5\": 5}\n",
        "# df=pd.DataFrame(somedict.items())\n",
        "# df.to_csv('mycsvfile.csv', index=False)\n",
        "# # with open('mycsvfile.csv','w+') as f:\n",
        "\n",
        "# #     w = csv.writer(f)\n",
        "\n",
        "# #     w.writerows(somedict.items())\n",
        "\n",
        "# points_dict = pd.read_csv(\"mycsvfile.csv\", index_col=False)\n",
        "# print(points_dict)\n",
        "# points_dict= points_dict.to_dict('dict')\n",
        "# print(points_dict)\n",
        "# # for key, points in points_dict.items():\n",
        "# #   print(key, points)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Time to Sec**"
      ],
      "metadata": {
        "id": "XHolKKTVa-Rm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "import time\n",
        "import numpy as np\n",
        "\n",
        "# [ [ [a11,a12] , [a21,-1] ] , [ [b11,b12] ] , None  ]\n",
        "# [a11,a12] -> 1 time pair\n",
        "# [ [a11,a12] , [a21,-1] ] -> trim points of an individual .wav\n",
        "# [ [b11,b12] ] -> trim points of another individual .wav\n",
        "# [ [ [a11,a12] , [a21,-1] ] , [ [b11,b12] , None]  ]-> trim points of all .wav\n",
        "# None -> null or kno trim points na thakle\n",
        "# -1 -> trim till the end\n",
        "# enter into raw_time then run, booooooooooooooooom! then just copy paste into trim_points.json\n",
        "\n",
        "raw_time=[\n",
        "[[0.0,0.15],[1.43,1.55],[2.15,2.23],[4.43,-1]]\n",
        "]\n",
        "\n",
        "for ind_time in raw_time:\n",
        "  time_sec=np.zeros((0,2))\n",
        "  if ind_time:\n",
        "    for t_pair in ind_time:\n",
        "      temp_time_sec=[]\n",
        "      time_format = '%M.%S'\n",
        "      for t in t_pair:\n",
        "        try: \n",
        "          x= time.strptime('{:.2f}'.format(t),time_format)\n",
        "          temp_time_sec.append(datetime.timedelta(minutes=x.tm_min,seconds=x.tm_sec).total_seconds())\n",
        "        except:\n",
        "          temp_time_sec.append(-1)\n",
        "      time_sec=np.vstack((time_sec,temp_time_sec))\n",
        "      temp_time_sec=[]\n",
        "    print(np.array2string(time_sec.astype(int), separator=', '), end='\\n\\n')\n",
        "  else:\n",
        "    print('null', end='\\n\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVvj1j6HbC5P",
        "outputId": "3f2bd813-959f-4e2d-c635-92c8f372cf4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  0,  15],\n",
            " [103, 115],\n",
            " [135, 143],\n",
            " [283,  -1]]\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "azFIQQMcOWVq",
        "E8YP26HSOy-z",
        "6Klg_-RbP10Q",
        "-vBE3qlwI-a1",
        "pisgwlkGAeSV",
        "J2eHNT-5L7Rh",
        "xoCOwNontBL3",
        "Ck6rJltyRFyq",
        "1KAPZojLuXZ_",
        "RTKIF3Ef2bR1",
        "JOoJoXO-zZU1",
        "Cx3FV5OV_W47",
        "aIJokXUO_h36",
        "uzzm4DPlYstS"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.10.0 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}